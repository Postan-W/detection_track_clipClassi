# 1.目标检测

## 1.1 模型训练

### 1.1.1 2024/6/6

- **数据**

  设置了两类normal_pass和unnormal_pass。使用了472张图片训练，157张图片验证，每张图片有1-2个目标，总体目标normal和unnormal的比值大概是6:4，接近7:3，所以说unnormal的比重较小，下次标注训练时要平衡下。

- **模型**

  使用的是ultralytics github的基于COCO8 0 pre-trained classes的YOLOv8m.pt。得到模型大小为50M。

- **超参数**

  batch=32;epoch=15

- **验证指标**

  ![1](record.assets/1.png)

- **推理测试**

  实际上翻阅闸机的情况非常少见，日常地铁里的视频流里面的乘客均是正常通过，所以测试时应该用真实的日常地铁站的记录视频，检验误报率是否高。

### 1.1.2 2024/6/17

训练了单标签模型，测试效果极差，连正常站立不在闸机处的人都会当结果识别出来。不作记录了，单表签方案不行。

### 1.1.3 待做 尝试三标签即正常行走，正常通过闸机，不正常通过闸机三种，这样更能降低误报，测试的时候只检测不正常通过闸机的情况。



# 2.目标追踪

## 2.1使用boxmot

## 2.2 使用ultralytics提供的追踪器

# 3.分类器

## 3.1CLIP分类器

metaclip效果不错，但模型太大

## 3.2 使用ultralytics提供的pose检测然后进行分类



# 4.综合

## 4.1 整个算法流程的推理速度





