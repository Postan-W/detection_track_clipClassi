# 关键点检测+关键点分类(分类器包含全连接网络和lightgbm，本文档以lightgbm为例)

# 1.数据标注

- **运行annotator.py即可标注关键点分类模型所需要的数据**。下面讲解自定义的一些操作。

- **在annotator.py中指定要标注的视频文件夹和输出文件路径，输出文件可以是.txt文件，建议标注自己的视频使用自己命名的.txt文件，以免和其他人的标注数据混在一起**。每标完一个视频将自动删除该视频。标注结果是以追加形式写入输出文件中，方便下次续标。

  ![image-20240716131844165](使用说明.assets/image-20240716131844165.png)

  

- **在pose_data_structure.py中可以自定义自己想要训练的动作**

  ![image-20240716144223915](使用说明.assets/image-20240716144223915.png)



- **下面模拟启动annotator.py后的操作**

  首先跳出一帧画面，并且画面上用**红框**标出了当前你要指定动作的对象

  ![image-20240716144540796](使用说明.assets/image-20240716144540796.png)

  按q退出画面。然后可在程序输入阻塞位置输入该对象的动作类型，如果动作类型不在你定义的动作里面，则无效，需要重新输入

  ![image-20240716144934664](使用说明.assets/image-20240716144934664.png)

  如上图还看到打印信息，提示各种动作标注的样本数

  **此时该标注信息经过一定规则(规则见pose_utils.py)的筛选，如果符合规则要求的话就被写入了输出文件中，如下图，每一行就是一个动作的标注信息**

  ![image-20240716145550035](使用说明.assets/image-20240716145550035.png)

  **然后指示框自动调到该帧的下一个目标，如果该帧没有下一个目标，则跳到下一帧，重复上述步骤。如果一帧中有多个目标，那么当前要标注是那个目标是用红框指示，而标注过的目标是非红框指示。**

- **其他**

  **如果当前目标不清晰或者遮挡过多，你认为不应该标注时，可以输入p跳过该目标。如果不想继续为该视频标注了，可以输入exit退出该视频，则程序自动读取文件夹下的下一个视频继续标注。**

- **标签索引化**

  假如当前我们标注完得到输出文件merged.txt，在训练模型前，需要将动作名称转为索引，使用pose_utils.py中的name2index函数：

  ![image-20240716151524591](使用说明.assets/image-20240716151524591.png)

  现在我们得到了模型训练的数据merged_indexed.txt,可以用来训练模型。

  ## 2.模型训练

  **运行classifier.py即可。下面讲解classifier.py**

  ```
  模型定义如下：
  class LightGBM:
      def __init__(self,params,train_data="./train_data/train_indexed.txt",model_save_path="./models/lgbm.txt",num_boost_round=1000,best_model="./models/best_gbm.joblib"):
          self.params = params
          self.train_data = train_data
          self.model_save_path = model_save_path
          self.num_boost_round = num_boost_round
          self.best_model = best_model
  .................
  ```

  **训练方法1：调用lgbm.train()**

  ![image-20240716162351110](使用说明.assets/image-20240716162351110.png)

  上面params中的其他参数可参考lightgbm模型教程进行调节。

  **训练方法2:网格搜索最佳参数**

  ![image-20240716163050521](使用说明.assets/image-20240716163050521.png)

  ![image-20240716163146543](使用说明.assets/image-20240716163146543.png)

# 3.推理

**运行pose_infer_lgbm.py**

![image-20240716163418764](使用说明.assets/image-20240716163418764.png)



# 4.其他

涉及到yolov8的关键点检测模型和和我们自己分类模型。请注意各个代码文件中模型路径的填写。

